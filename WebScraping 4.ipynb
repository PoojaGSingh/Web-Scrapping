{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94318f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\pooja\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: outcome in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\pooja\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pooja\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium \n",
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f69a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************\n",
    "# 1.Most Viewed Youtube Vedios\n",
    "#************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf1bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,StaleElementReferenceException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3292a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\pooja\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b2df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ebe3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Rank=[]\n",
    "    rank=driver.find_elements(By.XPATH,'//tr/td[1]')\n",
    "    for x in rank:\n",
    "        r = (x.text)\n",
    "        Rank.append(r)\n",
    "        \n",
    "    Name=[]\n",
    "    name=driver.find_elements(By.XPATH,'//tr/td[2]')\n",
    "    for x in name:\n",
    "        n = (x.text)\n",
    "        Name.append(n)\n",
    "\n",
    "\n",
    "\n",
    "    Artist= []\n",
    "    artist=driver.find_elements(By.XPATH,'//tr/td[3]')\n",
    "    for a in artist:\n",
    "        Artist.append(a.text)\n",
    "\n",
    "    \n",
    "    U_date =[]\n",
    "    date=driver.find_elements(By.XPATH,'//tr/td[5]')\n",
    "    for x in date:\n",
    "        d = (x.text)\n",
    "        U_date.append(d)\n",
    "        \n",
    "    Views =[]\n",
    "    views=driver.find_elements(By.XPATH,'//tr/td[4]')\n",
    "    for x in views:\n",
    "        v = (x.text)\n",
    "        Views.append(v)\n",
    "        \n",
    "except NoSuchElementExcetion as e:\n",
    "    Name.append(\"-\")\n",
    "    Rank.append(\"-\")\n",
    "    Artist.append(\"-\")\n",
    "    U_date.append(\"-\")\n",
    "    Views.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e507533",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ranks =Rank[1:31]\n",
    "Names  =Name[1:31]\n",
    "Artists = Artist[0:30]\n",
    "Upload_Date = U_date[0:30]\n",
    "View = Views[0:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c384d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print (len(Ranks),len(Names),len(Artists),len(Upload_Date),len(View))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0abd49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[24]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[25]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[41]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"[45]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[50]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                          \"Wheels on the Bus\"[24]   \n",
       "8    9.                                \"Uptown Funk\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
       "21  22.                                 \"Dark Horse\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.                             \"Girls Like You\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                             \"Lakdi Ki Kathi\"[50]   \n",
       "\n",
       "                                           Artist        Upload Date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.13  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.07  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.59  \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   5.96  \n",
       "4                                      Ed Sheeran   January 30, 2017   5.89  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.76  \n",
       "6                                       ChuChu TV      March 6, 2014   5.12  \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   4.84  \n",
       "8                                     Mark Ronson  November 19, 2014   4.80  \n",
       "9                                     Miroshka TV  February 27, 2018   4.79  \n",
       "10                                            Psy      July 15, 2012   4.66  \n",
       "11                                     Get Movies   January 31, 2012   4.52  \n",
       "12                                      El Chombo      April 5, 2018   4.21  \n",
       "13                                       Maroon 5   January 14, 2015   3.81  \n",
       "14                                     Katy Perry  September 5, 2013   3.72  \n",
       "15                                    OneRepublic       May 31, 2013   3.71  \n",
       "16                                     Crazy Frog      June 16, 2009   3.71  \n",
       "17                                  Justin Bieber   October 22, 2015   3.62  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.54  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.48  \n",
       "20                                        Shakira       June 4, 2010   3.44  \n",
       "21                                     Katy Perry  February 20, 2014   3.43  \n",
       "22                                    Alan Walker   December 3, 2015   3.39  \n",
       "23                                      Passenger      July 25, 2012   3.37  \n",
       "24                                       Maroon 5       May 31, 2018   3.36  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.35  \n",
       "26                               Enrique Iglesias     April 11, 2014   3.32  \n",
       "27                                    Major Lazer     March 22, 2015   3.32  \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.29  \n",
       "29                                   Jingle Toons      June 14, 2018   3.26  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':Ranks,'Name':Names,'Artist':Artists,'Upload Date':Upload_Date,'Views':View})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00dcc7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8a89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************\n",
    "#2.BCCI.TV\n",
    "#****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00acccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,StaleElementReferenceException,ElementNotInteractableException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d54af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\pooja\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04b16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f0a6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    menu=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/button\")\n",
    "    menu.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fb2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "international=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "international.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6df5c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "   \n",
    "       \n",
    "\n",
    "\n",
    "    mtitle=driver.find_elements(By.XPATH, '//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "    for x in mtitle:\n",
    "        t = (x.text.split(\"-\")[0])\n",
    "        M_Title.append(t)\n",
    "            \n",
    "    series=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "    for x in series:\n",
    "        s = (x.text)\n",
    "        Series.append(s)\n",
    "                \n",
    "    place=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "    for x in place:\n",
    "        p = (x.text.split(\"-\")[1])\n",
    "        Place.append(p)\n",
    "    \n",
    "        \n",
    "    date=driver.find_elements(By.XPATH ,'//h5[@class=\"ng-binding\"]')\n",
    "    for x in date:\n",
    "        d = (x.text)\n",
    "        Date.append(d)\n",
    "   \n",
    "    \n",
    "    time=driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "    for x in time:\n",
    "        i = (x.text)\n",
    "        Time.append(i)\n",
    "                \n",
    "    \n",
    "            \n",
    "except NoSuchElementFound as e:\n",
    "    M_Title.append(\"-\")\n",
    "    Series.append(\"-\")\n",
    "    Place.append(\"-\")\n",
    "    Date.append(\"-\")\n",
    "    Time.append(\"-\")\n",
    "    \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f1a0fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11 11 11 11\n"
     ]
    }
   ],
   "source": [
    "print (len(M_Title),len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "289fa5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Vidarbha Cricket Association Stadium, Nagpur</td>\n",
       "      <td>9 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>12 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>15 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>17 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>18 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>20 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,...</td>\n",
       "      <td>1 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>9 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA</td>\n",
       "      <td>19 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>MA Chidambaram Stadium, Chennai</td>\n",
       "      <td>22 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title                                       Series  \\\n",
       "0    1st Test   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "1    1st T20I                 ICC WOMENS T20 WORLD CUP 2023   \n",
       "2    2nd T20I                 ICC WOMENS T20 WORLD CUP 2023   \n",
       "3    2nd Test   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "4    3rd T20I                 ICC WOMENS T20 WORLD CUP 2023   \n",
       "5    4th T20I                 ICC WOMENS T20 WORLD CUP 2023   \n",
       "6    3rd Test   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "7    4th Test   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "8     1st ODI    AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "9     2nd ODI    AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "10    3rd ODI    AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23   \n",
       "\n",
       "                                                Place         Date  \\\n",
       "0        Vidarbha Cricket Association Stadium, Nagpur   9 FEB 2023   \n",
       "1                                 Newlands, Cape Town  12 FEB 2023   \n",
       "2                                 Newlands, Cape Town  15 FEB 2023   \n",
       "3                         Arun Jaitley Stadium, Delhi  17 FEB 2023   \n",
       "4                          St George's Park, Gqeberha  18 FEB 2023   \n",
       "5                          St George's Park, Gqeberha  20 FEB 2023   \n",
       "6    Himachal Pradesh Cricket Association Stadium,...   1 MAR 2023   \n",
       "7                    Narendra Modi Stadium, Ahmedabad   9 MAR 2023   \n",
       "8                            Wankhede Stadium, Mumbai  17 MAR 2023   \n",
       "9                         Dr YS Rajasekhara Reddy ACA  19 MAR 2023   \n",
       "10                    MA Chidambaram Stadium, Chennai  22 MAR 2023   \n",
       "\n",
       "           Time  \n",
       "0   9:30 AM IST  \n",
       "1   6:30 PM IST  \n",
       "2   6:30 PM IST  \n",
       "3   9:30 AM IST  \n",
       "4   6:30 PM IST  \n",
       "5   6:30 PM IST  \n",
       "6   9:30 AM IST  \n",
       "7   9:30 AM IST  \n",
       "8   1:30 PM IST  \n",
       "9   1:30 PM IST  \n",
       "10  1:30 PM IST  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Match Title':M_Title,'Series':Series,'Place':Place,'Date':Date,'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a773ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0d12624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************\n",
    "# 3.State Wise GDP -India\n",
    "#*****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dabb8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,StaleElementReferenceException,ElementNotInteractableException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7de1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\pooja\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e175bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77e5853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    economy=driver.find_element(By.XPATH,\"//html/body/div[2]/div[1]/div[2]/div[2]\")\n",
    "    economy.click()\n",
    "    india=driver.find_element(By.XPATH,\"//html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "    india.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fa49194",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP=driver.find_element(By.XPATH,\"//html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "GDP.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8211a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "Gdp=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "   \n",
    "       \n",
    "\n",
    "\n",
    "    rank=driver.find_elements(By.XPATH, '//table[@id=\"table_id\"]//td[1]')\n",
    "    for x in rank:\n",
    "        r = (x.text)\n",
    "        Rank.append(r)\n",
    "            \n",
    "    state=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[2]')\n",
    "    for x in state:\n",
    "        s = (x.text)\n",
    "        State.append(s)\n",
    "                \n",
    "    gsdp1=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[3]')\n",
    "    for x in gsdp1:\n",
    "        g1 = (x.text)\n",
    "        GSDP1.append(g1)\n",
    "    \n",
    "        \n",
    "    gsdp2=driver.find_elements(By.XPATH ,'//table[@id=\"table_id\"]//td[4]')\n",
    "    for x in gsdp2:\n",
    "        g2 = (x.text)\n",
    "        GSDP2.append(g2)\n",
    "   \n",
    "    \n",
    "    share=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[5]')\n",
    "    for x in share:\n",
    "        sh = (x.text)\n",
    "        Share.append(sh)\n",
    "        \n",
    "    gdp=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[6]')\n",
    "    for x in gdp:\n",
    "        g = (x.text)\n",
    "        Gdp.append(g)\n",
    "                \n",
    "    \n",
    "            \n",
    "except NoSuchElementFound as e:\n",
    "    Rank.append(\"-\")\n",
    "    State.append(\"-\")\n",
    "    GSDP1.append(\"-\")\n",
    "    GSDP2.append(\"-\")\n",
    "    Share.append(\"-\")\n",
    "    Gdp.append(\"-\")\n",
    "    \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7cf5138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 34 34 34 34 34\n"
     ]
    }
   ],
   "source": [
    "print (len(Rank),len(State),len(GSDP1),len(GSDP2),len(Share),len(Gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99d64f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>India</td>\n",
       "      <td>20,351,013</td>\n",
       "      <td>18,886,957</td>\n",
       "      <td></td>\n",
       "      <td>2,869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19) GSDP(19-20)   Share      GDP\n",
       "0     1                Maharashtra           -   2,632,792  13.94%  399.921\n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208   8.63%  247.629\n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764   8.39%  240.726\n",
       "3     4                    Gujarat           -   1,502,899   7.96%  228.290\n",
       "4     5                  Karnataka   1,631,977   1,493,127   7.91%  226.806\n",
       "5     6                West Bengal   1,253,832   1,089,898   5.77%  165.556\n",
       "6     7                  Rajasthan   1,020,989     942,586   4.99%  143.179\n",
       "7     8             Andhra Pradesh     972,782     862,957   4.57%  131.083\n",
       "8     9                  Telangana     969,604     861,031   4.56%  130.791\n",
       "9    10             Madhya Pradesh     906,672     809,592   4.29%  122.977\n",
       "10   11                     Kerala           -     781,653   4.14%  118.733\n",
       "11   12                      Delhi     856,112     774,870   4.10%  117.703\n",
       "12   13                    Haryana     831,610     734,163   3.89%  111.519\n",
       "13   14                      Bihar     611,804     530,363   2.81%   80.562\n",
       "14   15                     Punjab     574,760     526,376   2.79%   79.957\n",
       "15   16                     Odisha     521,275     487,805   2.58%   74.098\n",
       "16   17                      Assam           -     315,881   1.67%   47.982\n",
       "17   18               Chhattisgarh     329,180     304,063   1.61%   46.187\n",
       "18   19                  Jharkhand     328,598     297,204   1.57%   45.145\n",
       "19   20                Uttarakhand           -     245,895   1.30%   37.351\n",
       "20   21            Jammu & Kashmir           -     155,956   0.83%   23.690\n",
       "21   22           Himachal Pradesh     165,472     153,845   0.81%   23.369\n",
       "22   23                        Goa      80,449      73,170   0.39%   11.115\n",
       "23   24                    Tripura      55,984      49,845   0.26%    7.571\n",
       "24   25                 Chandigarh           -      42,114   0.22%    6.397\n",
       "25   26                 Puducherry      38,253      34,433   0.18%    5.230\n",
       "26   27                  Meghalaya      36,572      33,481   0.18%    5.086\n",
       "27   28                     Sikkim      32,496      28,723   0.15%    4.363\n",
       "28   29                    Manipur      31,790      27,870   0.15%    4.233\n",
       "29   30                   Nagaland           -      27,283   0.14%    4.144\n",
       "30   31          Arunachal Pradesh           -      24,603   0.13%    3.737\n",
       "31   32                    Mizoram      26,503      22,287   0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands           -           -       -        -\n",
       "33                           India  20,351,013  18,886,957            2,869"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':Rank,'State':State,'GSDP(18-19)':GSDP1,'GSDP(19-20)':GSDP2,'Share':Share,'GDP':Gdp})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65806b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6f04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************\n",
    "#4.Github - Trending Repositories\n",
    "#********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96ca16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,StaleElementReferenceException,ElementNotInteractableException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e3b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\pooja\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d73a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394b059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    menu=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button/span/span\")\n",
    "    menu.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26eb37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_source=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "o_source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb368e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_rep=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\")\n",
    "t_rep.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cadfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping URLs\n",
    "repo_urls = []\n",
    "\n",
    "repository = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "\n",
    "for i in repository:\n",
    "\n",
    "    repo_urls.append(i.get_attribute(\"href\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53d90a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repo_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43f9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data from every repository page\n",
    "Title=[]\n",
    "Dcrp =[]\n",
    "Lang = []\n",
    "C_Count=[]\n",
    "\n",
    "for i in repo_urls:\n",
    "\n",
    "    driver.get(i)\n",
    "\n",
    "    time.sleep(3)\n",
    "    \n",
    "     \n",
    "    try:\n",
    "        title=driver.find_element(By.XPATH, '//div[@class=\" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal\"]')\n",
    "        t = (title.text)\n",
    "        Title.append(t)\n",
    "        \n",
    "    except NoSuchElementException as e:\n",
    "        Title.append('-')\n",
    "\n",
    "   \n",
    "    try:\n",
    "        dcrp=driver.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        d = (dcrp.text)\n",
    "        Dcrp.append(d)\n",
    "        \n",
    "    except NoSuchElementException as e:\n",
    "        Dcrp.append('-')\n",
    "\n",
    "    \n",
    "    try:    \n",
    "        lang=driver.find_element(By.XPATH ,'//span[@class=\"color-fg-default text-bold mr-1\"]')\n",
    "        l = (lang.text)\n",
    "        Lang.append(l)\n",
    "        \n",
    "    except NoSuchElementException as e:\n",
    "        Lang.append('-')\n",
    "  \n",
    "      \n",
    "    Con = []                      \n",
    "    try:\n",
    "        ccount = driver.find_elements(By.XPATH,'//a[@class=\"Link--primary no-underline\"]')\n",
    "        for i in ccount:\n",
    "            c = (i.text)\n",
    "            Con.append(c)\n",
    "        C_Count.append(Con)\n",
    "           \n",
    "            \n",
    "\n",
    "    except NoSuchElementException:\n",
    "        C_Count.append('-') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845ef840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 25',\n",
       " ' 4',\n",
       " ' 21',\n",
       " ' 940',\n",
       " '-',\n",
       " ' 59',\n",
       " ' 11',\n",
       " ' 16',\n",
       " ' 2',\n",
       " ' 7',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " ' 6',\n",
       " ' 2',\n",
       " ' 15',\n",
       " ' 55',\n",
       " ' 34',\n",
       " ' 18',\n",
       " ' 190',\n",
       " ' 73',\n",
       " ' 3',\n",
       " ' 3',\n",
       " ' 3',\n",
       " ' 21']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contributors = []\n",
    "\n",
    "x=0\n",
    "while x < 25:\n",
    "    Contributors.append(C_Count[x][-1]) \n",
    "    \n",
    "    x= x+1\n",
    "\n",
    "C= []\n",
    "for i in Contributors:\n",
    "    if 'Contributors' in i:\n",
    "        C.append(i.strip('Contributors'))\n",
    "    else:\n",
    "        C.append('-')\n",
    "C\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ba61b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print (len(Title),len(Dcrp),len(Lang),len(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b96bca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "      <th>Contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuergaosi233\\n/\\nwechat-chatgpt\\nPublic</td>\n",
       "      <td>Use ChatGPT On Wechat via wechaty</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AutumnWhj\\n/\\nChatGPT-wechat-bot\\nPublic</td>\n",
       "      <td>ChatGPT for wechat https://github.com/AutumnWh...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motion-canvas\\n/\\nmotion-canvas\\nPublic</td>\n",
       "      <td>Visualize Complex Ideas Programmatically</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheAlgorithms\\n/\\nPython\\nPublic</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>Python</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>djun\\n/\\nwechatbot\\nPublic</td>\n",
       "      <td>为个人微信接入ChatGPT</td>\n",
       "      <td>Go</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f\\n/\\nawesome-chatgpt-prompts\\nPublic</td>\n",
       "      <td>This repo includes ChatGPT prompt curation to ...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zero6992\\n/\\nchatGPT-discord-bot\\nPublic template</td>\n",
       "      <td>Integrate ChatGPT into your own discord bot</td>\n",
       "      <td>Python</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acikkaynak\\n/\\ndeprem-yardim-backend\\nPublic a...</td>\n",
       "      <td>afetharita.com backend projesi</td>\n",
       "      <td>Python</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>samim23\\n/\\npolymath\\nPublic</td>\n",
       "      <td>Convert any music library into a music product...</td>\n",
       "      <td>Python</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zhayujie\\n/\\nchatgpt-on-wechat\\nPublic</td>\n",
       "      <td>使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wecha...</td>\n",
       "      <td>Python</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BaRRaKudaRain\\n/\\nPCem-ROMs\\nPublic</td>\n",
       "      <td>This is a collection of requiered ROMs files f...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>eliaszon\\n/\\nProgrammers-Overseas-Job-Intervie...</td>\n",
       "      <td>🏂🏻 程序员海外工作/英文面试手册</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AIGCT\\n/\\nEASYChatGPT\\nPublic</td>\n",
       "      <td>This is an application project of 'chatgpt',on...</td>\n",
       "      <td>Python</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PlexPt\\n/\\nawesome-chatgpt-prompts-zh\\nPublic</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>houko\\n/\\nwechatgpt\\nPublic</td>\n",
       "      <td>wechatgpt golang版 chatgpt机器人(可docker部署)，目前支持微信...</td>\n",
       "      <td>Go</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lencx\\n/\\nChatGPT\\nPublic</td>\n",
       "      <td>🔮 ChatGPT Desktop Application (Mac, Windows an...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>acheong08\\n/\\nChatGPT\\nPublic</td>\n",
       "      <td>Reverse engineered ChatGPT API</td>\n",
       "      <td>Python</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>openai\\n/\\nopenai-cookbook\\nPublic</td>\n",
       "      <td>Examples and guides for using the OpenAI API</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eatmoreapple\\n/\\nopenwechat\\nPublic</td>\n",
       "      <td>golang微信SDK</td>\n",
       "      <td>Go</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cezaraugusto\\n/\\nYou-Dont-Know-JS\\nPublic</td>\n",
       "      <td>📗📒 (PT-Br translation) JS Book Series.</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>acikkaynak\\n/\\ndeprem-yardim-frontend\\nPublic</td>\n",
       "      <td>afetharita.com frontend projesi. https://rc.af...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>shajen\\n/\\nrtl-sdr-scanner-cpp\\nPublic</td>\n",
       "      <td>-</td>\n",
       "      <td>C++</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fndroid\\n/\\nclash_for_windows_pkg\\nPublic</td>\n",
       "      <td>A Windows/macOS GUI based on Clash</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kyujin-cho\\n/\\npixel-volte-patch\\nPublic</td>\n",
       "      <td>Rootless replacement for persist.dbg.volte_ava...</td>\n",
       "      <td>Kotlin</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>acikkaynak\\n/\\nyardim-agi-flutter\\nPublic</td>\n",
       "      <td>Bu uygulama, ihtiyaç sahibi depremzedelerin ha...</td>\n",
       "      <td>Dart</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0             fuergaosi233\\n/\\nwechat-chatgpt\\nPublic   \n",
       "1            AutumnWhj\\n/\\nChatGPT-wechat-bot\\nPublic   \n",
       "2             motion-canvas\\n/\\nmotion-canvas\\nPublic   \n",
       "3                    TheAlgorithms\\n/\\nPython\\nPublic   \n",
       "4                          djun\\n/\\nwechatbot\\nPublic   \n",
       "5               f\\n/\\nawesome-chatgpt-prompts\\nPublic   \n",
       "6   Zero6992\\n/\\nchatGPT-discord-bot\\nPublic template   \n",
       "7   acikkaynak\\n/\\ndeprem-yardim-backend\\nPublic a...   \n",
       "8                        samim23\\n/\\npolymath\\nPublic   \n",
       "9              zhayujie\\n/\\nchatgpt-on-wechat\\nPublic   \n",
       "10                BaRRaKudaRain\\n/\\nPCem-ROMs\\nPublic   \n",
       "11  eliaszon\\n/\\nProgrammers-Overseas-Job-Intervie...   \n",
       "12                      AIGCT\\n/\\nEASYChatGPT\\nPublic   \n",
       "13      PlexPt\\n/\\nawesome-chatgpt-prompts-zh\\nPublic   \n",
       "14                        houko\\n/\\nwechatgpt\\nPublic   \n",
       "15                          lencx\\n/\\nChatGPT\\nPublic   \n",
       "16                      acheong08\\n/\\nChatGPT\\nPublic   \n",
       "17                 openai\\n/\\nopenai-cookbook\\nPublic   \n",
       "18                eatmoreapple\\n/\\nopenwechat\\nPublic   \n",
       "19          cezaraugusto\\n/\\nYou-Dont-Know-JS\\nPublic   \n",
       "20      acikkaynak\\n/\\ndeprem-yardim-frontend\\nPublic   \n",
       "21             shajen\\n/\\nrtl-sdr-scanner-cpp\\nPublic   \n",
       "22          Fndroid\\n/\\nclash_for_windows_pkg\\nPublic   \n",
       "23           kyujin-cho\\n/\\npixel-volte-patch\\nPublic   \n",
       "24          acikkaynak\\n/\\nyardim-agi-flutter\\nPublic   \n",
       "\n",
       "                                          Description          Language  \\\n",
       "0                   Use ChatGPT On Wechat via wechaty        TypeScript   \n",
       "1   ChatGPT for wechat https://github.com/AutumnWh...        TypeScript   \n",
       "2            Visualize Complex Ideas Programmatically        TypeScript   \n",
       "3                All Algorithms implemented in Python            Python   \n",
       "4                                      为个人微信接入ChatGPT                Go   \n",
       "5   This repo includes ChatGPT prompt curation to ...              HTML   \n",
       "6         Integrate ChatGPT into your own discord bot            Python   \n",
       "7                      afetharita.com backend projesi            Python   \n",
       "8   Convert any music library into a music product...            Python   \n",
       "9   使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wecha...            Python   \n",
       "10  This is a collection of requiered ROMs files f...                 -   \n",
       "11                                  🏂🏻 程序员海外工作/英文面试手册                 -   \n",
       "12  This is an application project of 'chatgpt',on...            Python   \n",
       "13                ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。                 -   \n",
       "14  wechatgpt golang版 chatgpt机器人(可docker部署)，目前支持微信...                Go   \n",
       "15  🔮 ChatGPT Desktop Application (Mac, Windows an...              Rust   \n",
       "16                     Reverse engineered ChatGPT API            Python   \n",
       "17       Examples and guides for using the OpenAI API  Jupyter Notebook   \n",
       "18                                        golang微信SDK                Go   \n",
       "19             📗📒 (PT-Br translation) JS Book Series.        JavaScript   \n",
       "20  afetharita.com frontend projesi. https://rc.af...        TypeScript   \n",
       "21                                                  -               C++   \n",
       "22                 A Windows/macOS GUI based on Clash                 -   \n",
       "23  Rootless replacement for persist.dbg.volte_ava...            Kotlin   \n",
       "24  Bu uygulama, ihtiyaç sahibi depremzedelerin ha...              Dart   \n",
       "\n",
       "   Contributors  \n",
       "0            25  \n",
       "1             4  \n",
       "2            21  \n",
       "3           940  \n",
       "4             -  \n",
       "5            59  \n",
       "6            11  \n",
       "7            16  \n",
       "8             2  \n",
       "9             7  \n",
       "10            -  \n",
       "11            -  \n",
       "12            -  \n",
       "13            6  \n",
       "14            2  \n",
       "15           15  \n",
       "16           55  \n",
       "17           34  \n",
       "18           18  \n",
       "19          190  \n",
       "20           73  \n",
       "21            3  \n",
       "22            3  \n",
       "23            3  \n",
       "24           21  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':Title,'Description':Dcrp,'Language':Lang,'Contributors':C})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8de5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90753b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************\n",
    "# 100 Billboard Songs\n",
    "#****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844a0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,StaleElementReferenceException,ElementNotInteractableException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3832d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\pooja\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c052aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e07b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    menu=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\")\n",
    "    menu.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d232a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chart=driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button\")\n",
    "    chart.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c35984",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot100=driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a\")\n",
    "hot100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f00321",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song=[]\n",
    "Artist =[]\n",
    "L_rank = []\n",
    "P_rank=[]\n",
    "W_chart=[]\n",
    "\n",
    "try:\n",
    "    song=driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "    for i in song:\n",
    "        s = (i.text)\n",
    "        Song.append(s)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Song.append('-')\n",
    "\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[1]/span')\n",
    "    for i in artist:\n",
    "        a = (i.text)\n",
    "        Artist.append(a)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Artist.append('-')\n",
    "\n",
    "    \n",
    "try:    \n",
    "    lrank=driver.find_elements(By.XPATH ,'//li[@class=\"lrv-u-width-100p\"]/ul/li[4]/span')\n",
    "    for i in lrank:\n",
    "        l = (i.text)\n",
    "        L_rank.append(l)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    L_rank.append('-')\n",
    "    \n",
    "try:    \n",
    "    prank=driver.find_elements(By.XPATH ,'//li[@class=\"lrv-u-width-100p\"]/ul/li[5]/span')\n",
    "    for i in prank:\n",
    "        p = (i.text)\n",
    "        P_rank.append(p)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    P_rank.append('-')\n",
    "    \n",
    "try:    \n",
    "    wchart=driver.find_elements(By.XPATH ,'//li[@class=\"lrv-u-width-100p\"]/ul/li[6]/span')\n",
    "    for i in wchart:\n",
    "        c = (i.text)\n",
    "        W_chart.append(c)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    W_chart.append('-')\n",
    "  \n",
    "      \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28b20ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print (len(Song),len(Artist),len(L_rank),len(P_rank),len(W_chart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13aa91e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Rank_Last Week</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hey Mor</td>\n",
       "      <td>Ozuna Featuring Feid</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Gato de Noche</td>\n",
       "      <td>Nengo Flow &amp; Bad Bunny</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heart To Heart</td>\n",
       "      <td>Mac DeMarco</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Never Gonna Not Dance Again</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dancin' In The Country</td>\n",
       "      <td>Tyler Hubbard</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Song                                Artist  \\\n",
       "0                       Flowers                           Miley Cyrus   \n",
       "1                     Kill Bill                                   SZA   \n",
       "2                      Creepin'  Metro Boomin, The Weeknd & 21 Savage   \n",
       "3                     Anti-Hero                          Taylor Swift   \n",
       "4                        Unholy                Sam Smith & Kim Petras   \n",
       "..                          ...                                   ...   \n",
       "95                      Hey Mor                  Ozuna Featuring Feid   \n",
       "96                Gato de Noche                Nengo Flow & Bad Bunny   \n",
       "97               Heart To Heart                           Mac DeMarco   \n",
       "98  Never Gonna Not Dance Again                                  P!nk   \n",
       "99       Dancin' In The Country                         Tyler Hubbard   \n",
       "\n",
       "   Rank_Last Week Peak Rank Weeks on chart  \n",
       "0               1         1              3  \n",
       "1               2         2              8  \n",
       "2               4         3              9  \n",
       "3               3         1             15  \n",
       "4               5         1             19  \n",
       "..            ...       ...            ...  \n",
       "95              -        96              1  \n",
       "96             85        60              6  \n",
       "97             83        83              3  \n",
       "98              -        99              1  \n",
       "99              -       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Song':Song,'Artist':Artist,'Rank_Last Week':L_rank,'Peak Rank':P_rank,'Weeks on chart':W_chart})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e6cf81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41de1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************\n",
    "# 6.HighestSelling Novel:- Gaurdian\n",
    "#*****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb196bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,StaleElementReferenceException,ElementNotInteractableException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e980a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\pooja\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e13b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba30ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book=[]\n",
    "Author =[]\n",
    "Volume = []\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "try:\n",
    "    book=driver.find_elements(By.XPATH, '//tbody/tr/td[2]')\n",
    "    for i in book:\n",
    "        b = (i.text)\n",
    "        Book.append(b)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Book.append('-')\n",
    "\n",
    "try:\n",
    "    author=driver.find_elements(By.XPATH,'//tbody/tr/td[3]')\n",
    "    for i in author:\n",
    "        a = (i.text)\n",
    "        Author.append(a)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Author.append('-')\n",
    "\n",
    "    \n",
    "try:    \n",
    "    volume=driver.find_elements(By.XPATH ,'//tbody/tr/td[4]')\n",
    "    for i in volume:\n",
    "        v = (i.text)\n",
    "        Volume.append(v)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Volume.append('-')\n",
    "    \n",
    "try:    \n",
    "    publisher=driver.find_elements(By.XPATH ,'//tbody/tr/td[5]')\n",
    "    for i in publisher:\n",
    "        p = (i.text)\n",
    "        Publisher.append(p)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Publisher.append('-')\n",
    "    \n",
    "try:    \n",
    "    genre=driver.find_elements(By.XPATH ,'//tbody/tr/td[6]')\n",
    "    for i in genre:\n",
    "        g = (i.text)\n",
    "        Genre.append(g)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Genre.append('-')\n",
    "  \n",
    "      \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6477ff30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print (len(Book),len(Author),len(Volume),len(Publisher),len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ac1ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Book            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "       Volume        Publisher                        Genre  \n",
       "0   5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1   4,475,152       Bloomsbury           Children's Fiction  \n",
       "2   4,200,654       Bloomsbury           Children's Fiction  \n",
       "3   4,179,479       Bloomsbury           Children's Fiction  \n",
       "4   3,758,936     Random House              Romance & Sagas  \n",
       "..        ...              ...                          ...  \n",
       "95    807,311     Random House   General & Literary Fiction  \n",
       "96    794,201          Penguin        Food & Drink: General  \n",
       "97    792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98    791,507            Orion           Biography: General  \n",
       "99    791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Book':Book,'Author':Author,'Volume':Volume,'Publisher':Publisher,'Genre':Genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557765c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045fbf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************\n",
    "# IMDB : TV Series\n",
    "#**********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c172160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,StaleElementReferenceException,ElementNotInteractableException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28d4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\pooja\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83df90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46dc3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name =[]\n",
    "Y_span =[]\n",
    "Genre = []\n",
    "Runtime=[]\n",
    "Ratings=[]\n",
    "Votes = []\n",
    "\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH, '//h3[@class=\"lister-item-header\"]/a')\n",
    "    for i in name:\n",
    "        n = (i.text)\n",
    "        Name.append(n)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Name.append('-')\n",
    "\n",
    "try:\n",
    "    yspan=driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "    for i in yspan:\n",
    "        y = (i.text)\n",
    "        Y_span.append(y)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Y_span.append('-')\n",
    "\n",
    "    \n",
    "try:    \n",
    "    genre=driver.find_elements(By.XPATH ,'//span[@class=\"genre\"]')\n",
    "    for i in genre:\n",
    "        g = (i.text)\n",
    "        Genre.append(g)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Genre.append('-')\n",
    "    \n",
    "try:    \n",
    "    rtime=driver.find_elements(By.XPATH ,'//span[@class=\"runtime\"]')\n",
    "    for i in rtime:\n",
    "        r = (i.text)\n",
    "        Runtime.append(r)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Runtime.append('-')\n",
    "    \n",
    "try:    \n",
    "    ratings=driver.find_elements(By.XPATH ,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "    for i in ratings:\n",
    "        rs = (i.text)\n",
    "        Ratings.append(rs)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Ratings.append('-')\n",
    "    \n",
    "try:    \n",
    "    votes=driver.find_elements(By.NAME ,'nv')\n",
    "    for i in votes:\n",
    "        v = (i.text)\n",
    "        Votes.append(v)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Votes.append('-')\n",
    "  \n",
    "      \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5610865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print (len(Name),len(Y_span),len(Genre),len(Runtime),len(Ratings),len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce86796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,122,716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,210,732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,006,763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>297,072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>256,003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>62,604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>202,856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>250,671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "    Runtime Ratings      Votes  \n",
       "0    57 min     9.2  2,122,716  \n",
       "1    51 min     8.7  1,210,732  \n",
       "2    44 min     8.1  1,006,763  \n",
       "3    60 min     7.5    297,072  \n",
       "4    43 min     7.6    256,003  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,725  \n",
       "96   50 min     7.8     62,604  \n",
       "97   42 min     8.1    202,856  \n",
       "98   45 min     7.1     42,041  \n",
       "99  572 min     8.6    250,671  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame ({'Name':Name,'Year Span':Y_span,'Genre':Genre,'Runtime':Runtime,'Ratings':Ratings,'Votes':Votes})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa710f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40a7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************************************\n",
    "#9. UCI Repositories :Datasets\n",
    "#******************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae1a6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException,StaleElementReferenceException,ElementNotInteractableException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac80c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\pooja\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e46057f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f0430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "datasets.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09995a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name =[]\n",
    "Type =[]\n",
    "Task = []\n",
    "Attribute =[]\n",
    "No_instances=[]\n",
    "No_attributes = []\n",
    "Year = []\n",
    "\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH, '//table/tbody/tr/td[2]/p/b/a')\n",
    "    for i in name:\n",
    "        n = (i.text)\n",
    "        if n == (\"\"):\n",
    "            Name.append(\"-\")\n",
    "        else:\n",
    "            Name.append(n)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Name.append('-')\n",
    "\n",
    "try:\n",
    "    typ=driver.find_elements(By.XPATH,'//table[2]/tbody/tr/td[2]/p')\n",
    "    for i in typ:\n",
    "        t = (i.text)\n",
    "        if t == (\" \"):\n",
    "            Type.append(\"-\")\n",
    "        else:\n",
    "            Type.append(t)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Type.append('-')\n",
    "Type = Type[1:]\n",
    "\n",
    "\n",
    "    \n",
    "try:    \n",
    "    task=driver.find_elements(By.XPATH ,'//tbody/tr/td[3]/p')\n",
    "    for i in task:\n",
    "        tk = (i.text)\n",
    "        if tk == (\" \"):\n",
    "            Task.append(\"-\")\n",
    "        else:\n",
    "            Task.append(tk)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Task.append('-')\n",
    "Task = Task[1:623]\n",
    "    \n",
    "try:    \n",
    "    attribute=driver.find_elements(By.XPATH ,'//tbody/tr/td[4]/p')\n",
    "    for i in attribute:\n",
    "        a = (i.text)\n",
    "        if a == (\" \"):\n",
    "            Attribute.append(\"-\")\n",
    "        else:\n",
    "            Attribute.append(a)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Attribute.append('-')\n",
    "Attribute = Attribute[1:]\n",
    "\n",
    "try:    \n",
    "    ninstances=driver.find_elements(By.XPATH ,'//tbody/tr/td[5]/p')\n",
    "    for i in ninstances:\n",
    "        ni = (i.text)\n",
    "        if ni == (\" \"):\n",
    "            No_instances.append(\"-\")\n",
    "        else:\n",
    "            No_instances.append(ni)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    No_instances.append('-')\n",
    "No_instances = No_instances[1:]\n",
    "    \n",
    "try:    \n",
    "    nattributes=driver.find_elements(By.XPATH ,'//tbody/tr/td[6]/p')\n",
    "    for i in nattributes:\n",
    "        na = (i.text)\n",
    "        if na == (\" \"):\n",
    "            No_attributes.append(\"-\")\n",
    "        else:\n",
    "            No_attributes.append(na)\n",
    "\n",
    "except NoSuchElementException as e:\n",
    "    No_attributes.append('-')\n",
    "    \n",
    "No_attributes = No_attributes[1:]\n",
    "    \n",
    "try:    \n",
    "    year=driver.find_elements(By.XPATH ,'//tbody/tr/td[7]/p')\n",
    "    for i in year:\n",
    "        y = (i.text)\n",
    "        if y == (\" \"):\n",
    "            Year.append(\"-\")\n",
    "        else:\n",
    "            Year.append(y)\n",
    "        \n",
    "except NoSuchElementException as e:\n",
    "    Year.append('-')\n",
    "    \n",
    "Year = Year[1:]\n",
    "    \n",
    "  \n",
    "      \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb921c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 622 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "print (len(Name),len(Type),len(Task),len(Attribute),len(No_instances),len(No_attributes),len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5089d330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No. of Instances</th>\n",
       "      <th>No. of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>-</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Dataset  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                             -  Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                           -       Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No. of Instances No. of Attributes   Year  \n",
       "0    Categorical, Integer, Real             4177                 8   1995   \n",
       "1          Categorical, Integer            48842                14   1996   \n",
       "2    Categorical, Integer, Real              798                38       -  \n",
       "3                   Categorical            37711               294   1998   \n",
       "4    Categorical, Integer, Real              452               279   1998   \n",
       "..                           ...              ...               ...    ...  \n",
       "617               Integer, Real            75840               525   2020   \n",
       "618               Integer, Real              400                50   2020   \n",
       "619                            -            1014                 7   2020   \n",
       "620                        Real            10129                16   2021   \n",
       "621                        Real             4000                 2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Dataset':Name,'Data Type':Type,'Task':Task,'Attribute Type':Attribute,'No. of Instances':No_instances,'No. of Attributes':No_attributes,'Year':Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1e5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ace71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
